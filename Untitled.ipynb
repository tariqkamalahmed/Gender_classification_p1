{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodecsv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import csv                             \n",
    "import nltk\n",
    "nltk.data.path.append(\"/Users/Shared/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path, Text=None):\n",
    "    with open(path, 'r',encoding='utf-8') as f:\n",
    "        reader = csv.reader(f,delimiter=',')\n",
    "        for line in reader:\n",
    "            (Lines, Character, Gender) = parseReview(line)\n",
    "            rawData.append((Lines,Character, Gender))\n",
    "\n",
    "def splitData(percentage):     # A method to split the data between trainData and testData \n",
    "    dataSamples = len(rawData)\n",
    "    halfOfData = int(len(rawData)/2)\n",
    "    trainingSamples = int((percentage*dataSamples)/2)\n",
    "    for (Lines, _, Gender) in rawData[:trainingSamples] + rawData[halfOfData:halfOfData+trainingSamples]:\n",
    "        trainData.append((toFeatureVector(preProcess(Lines)),Gender))\n",
    "    for (Lines, _, Gender) in rawData[trainingSamples:halfOfData] + rawData[halfOfData+trainingSamples:]:\n",
    "        testData.append((toFeatureVector(preProcess(Lines)),Gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseReview(reviewLine):\n",
    "    \n",
    "    Lines = reviewLine[0]\n",
    "    Character = reviewLine[1]\n",
    "    Gender = reviewLine[2]\n",
    "    \n",
    "    return reviewLine[0], reviewLine[1], reviewLine[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "    \n",
    "# Text processing with Scikit-Learn, basics\n",
    "# Creating a vectorizer that can be used to extract a bag of words\n",
    "# representation from documents\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmer = PorterStemmer()\n",
    "# Input: a string of one review\n",
    "def preProcess(text):\n",
    "\n",
    "\n",
    "    pos_tags = [x[1] for x in pos_tag(text)] \n",
    "    text = word_tokenize(text)\n",
    "    b = []\n",
    "    for word in text:\n",
    "        if word.isalpha(): # removing punctuation\n",
    "            if word not in stop_words: # removing stopwords or \"too common\" words\n",
    "                word = word.lower() # converting all letters to lower case \n",
    "                word = wordnet_lemmatizer.lemmatize(word)  # lemmatisation\n",
    "                word = stemmer.stem(word) # Using standard stemmer from the nltk\n",
    "                b.append(word)\n",
    "     \n",
    "    return b,pos_tags #returns both pos-tags and a list of words that have been pre-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDict = {} # A global dictionary of features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "\n",
    "def toFeatureVector(put):\n",
    "    tokens,pos_tags = put\n",
    "# Should return a dictionary containing features as keys, and weights as values\n",
    "    featureVector = {}\n",
    "    for token in tokens: #split words into tokens and pos\n",
    "        if token not in featureVector:\n",
    "            featureVector[token] = 1.0\n",
    "        else:\n",
    "            featureVector[token] = float(featureVector[token] + 1)\n",
    "            \n",
    "        if token not in featureDict:\n",
    "            featureDict[token] = 1.0\n",
    "        else:\n",
    "            featureDict[token] = float(featureDict[token] + 1)\n",
    "\n",
    "        \n",
    "    for pos in pos_tags: #split words into tokens and pos\n",
    "        if pos not in featureVector:\n",
    "            featureVector[pos] = 1.0\n",
    "        else:\n",
    "            featureVector[pos] = float(featureVector[pos] + 1)\n",
    "            \n",
    "        if pos not in featureDict:\n",
    "            featureDict[pos] = 1.0\n",
    "        else:\n",
    "            featureDict[pos] = float(featureDict[pos] + 1)    \n",
    "            \n",
    "    \n",
    "    for i in range(1, len(tokens)):\n",
    "            bigram = tokens[i-1] + \" \" + tokens[i]\n",
    "            try:\n",
    "                featureVector[bigram] = 1 #+= 1.0/len(tokens)\n",
    "            except KeyError:\n",
    "                featureVector[bigram] = 1 #= 1.0/len(tokens)\n",
    "            try:\n",
    "                featureVector[bigram] += 1.0\n",
    "            except KeyError:\n",
    "                featureVector[bigram] = 1.0\n",
    "                \n",
    "    \n",
    "    sentence = len(tokens)\n",
    "    featureDict['length']= sentence\n",
    "        \n",
    "    return featureVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "def trainClassifier(trainData):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('tfidf', TfidfTransformer()),('chi2', SelectKBest(chi2, k=15000)),('svc', LinearSVC(loss = 'hinge'))])\n",
    "    return SklearnClassifier(pipeline).train(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predictLabels(reviewSamples, classifier):\n",
    "    return classifier.classify_many(map(lambda t: t[0], reviewSamples))\n",
    "\n",
    "def predictLabel(text, classifier):\n",
    "    return classifier.classify(toFeatureVector(preProcess(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# loading reviews\n",
    "rawData = []         \n",
    "trainData = []        \n",
    "testData = []         \n",
    "\n",
    "\n",
    "# references to the data files\n",
    "Path = 'training.csv'\n",
    "\n",
    "loadData(Path) \n",
    "\n",
    "splitData(0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Done training!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.56      0.48      0.52      1017\n",
      "        male       0.54      0.63      0.58      1006\n",
      "\n",
      "    accuracy                           0.55      2023\n",
      "   macro avg       0.55      0.55      0.55      2023\n",
      "weighted avg       0.55      0.55      0.55      2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the tranin data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    classifier = trainClassifier(trainData)  # train the classifier\n",
    "    testTrue = [t[1] for t in testData]   # get the ground-truth labels from the data\n",
    "    testPred = predictLabels(testData, classifier)  # classify the test data to get predicted labels\n",
    "    print(\"Done training!\")\n",
    "    print(classification_report(testTrue, testPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # references to the data files\n",
    "# rawData = []         \n",
    "# trainData = []        \n",
    "# testData = []   \n",
    "\n",
    "\n",
    "# Path = 'test.csv'\n",
    "# loadData(Path) \n",
    "\n",
    "\n",
    "# splitData(0)\n",
    "\n",
    "# functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "# if functions_complete:\n",
    "#     testTrue = [t[1] for t in testData]   # get the ground-truth labels from the data\n",
    "#     testPred = predictLabels(testData, classifier)  # classify the test data to get predicted labels\n",
    "#     print(\"Done training!\")\n",
    "#     print(classification_report(testTrue, testPred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def confusion_matrix_heatmap(testTrue, testPred):\n",
    "#     \"\"\"Function to plot a confusion matrix\"\"\"\n",
    "#     labels = list(set(testPred))   # get the labels in the y_test\n",
    "#     # print(labels)\n",
    "#     cm = confusion_matrix(testTrue, testPred, labels)\n",
    "#     fig = plt.figure(figsize=(10,10))\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     cax = ax.matshow(cm)\n",
    "#     plt.title('Confusion matrix of the classifier')\n",
    "#     fig.colorbar(cax)\n",
    "#     ax.set_xticks(np.arange(len(labels)))\n",
    "#     ax.set_yticks(np.arange(len(labels)))\n",
    "#     ax.set_xticklabels( labels, rotation=0)\n",
    "#     ax.set_yticklabels( labels)\n",
    "\n",
    "#     for i in range(len(cm)):\n",
    "#         for j in range(len(cm)):\n",
    "#             text = ax.text(j, i, cm[i, j],\n",
    "#                            ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('True')\n",
    "#     #fig.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix_heatmap(testTrue, testPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
